"""
Background-Service f√ºr periodische OCR-Verarbeitung neuer PDF-Dateien.
Erweitert um Document Processing System f√ºr Wareneingang-Dokumente.
"""

import asyncio
import logging
import os
import shutil
import tempfile
from pathlib import Path
from typing import Set

from ..config.settings import PDF_INPUT_DIR
from ..models.dokument import Dokument
from ..services.ocr_service import OCRService

logger = logging.getLogger(__name__)

class OCRScheduler:
    """Background-Service f√ºr periodische OCR-Verarbeitung mit Document Processing."""
    
    def __init__(self, check_interval: int = 30):
        """
        Args:
            check_interval: Pr√ºfintervall in Sekunden (Standard: 30s)
        """
        self.check_interval = check_interval
        self.running = False
        self.processed_files: Set[str] = set()
        self._task = None
        self._document_processor_manager = None
    
    async def start(self):
        """Startet den Background-Scheduler."""
        if self.running:
            logger.warning("OCR-Scheduler l√§uft bereits")
            return
        
        self.running = True
        logger.info(f"OCR-Scheduler gestartet - Pr√ºfintervall: {self.check_interval}s")
        
        # Document Processing System initialisieren
        await self._init_document_processing()
        
        # Initial bereits verarbeitete Dateien laden
        self._load_processed_files()
        
        # Background-Task starten
        self._task = asyncio.create_task(self._background_loop())
    
    async def stop(self):
        """Stoppt den Background-Scheduler."""
        if not self.running:
            return
        
        self.running = False
        
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        
        logger.info("OCR-Scheduler gestoppt")
    
    async def _init_document_processing(self):
        """Initialisiert das Document Processing System."""
        try:
            # Lazy Import um Circular Imports zu vermeiden
            from ..services.document_processing import document_processor_manager
            
            self._document_processor_manager = document_processor_manager
            
            processors = self._document_processor_manager.get_registered_processors()
            logger.info(f"üìã Document Processors geladen: {', '.join(processors)}")
            
        except ImportError as e:
            logger.warning(f"Document Processing System nicht verf√ºgbar: {e}")
            self._document_processor_manager = None
        except Exception as e:
            logger.error(f"Fehler beim Initialisieren des Document Processing: {e}")
            self._document_processor_manager = None
    
    def _load_processed_files(self):
        """L√§dt bereits verarbeitete Dateien beim Start."""
        try:
            for filename in os.listdir(PDF_INPUT_DIR):
                if filename.lower().endswith('.pdf'):
                    file_path = os.path.join(PDF_INPUT_DIR, filename)
                    ocr_marker = file_path + '.ocr_processed'
                    doc_marker = file_path + '.doc_processed'
                    
                    # Als verarbeitet markieren wenn beide Marker vorhanden sind
                    if os.path.exists(ocr_marker) and os.path.exists(doc_marker):
                        self.processed_files.add(filename)
            
            logger.info(f"Bereits vollst√§ndig verarbeitete Dateien geladen: {len(self.processed_files)}")
            
        except Exception as e:
            logger.error(f"Fehler beim Laden verarbeiteter Dateien: {e}")
    
    async def _background_loop(self):
        """Haupt-Background-Loop f√ºr periodische Pr√ºfung."""
        while self.running:
            try:
                await self._check_and_process_files()
                await asyncio.sleep(self.check_interval)
                
            except asyncio.CancelledError:
                logger.info("OCR-Scheduler wurde abgebrochen")
                break
            except Exception as e:
                logger.error(f"Fehler im OCR-Scheduler: {e}")
                # Bei Fehlern kurz warten und weitermachen
                await asyncio.sleep(5)
    
    async def _check_and_process_files(self):
        """Pr√ºft auf neue Dateien und verarbeitet sie."""
        try:
            if not os.path.exists(PDF_INPUT_DIR):
                return
            
            files_to_process = []
            
            # ALLE PDF-Dateien pr√ºfen (nicht nur unverarbeitete)
            for filename in os.listdir(PDF_INPUT_DIR):
                if filename.lower().endswith('.pdf'):
                    file_path = os.path.join(PDF_INPUT_DIR, filename)
                    
                    # Pr√ºfen ob in DB vorhanden
                    in_database = self._is_file_in_database(filename)
                    
                    # OCR-Status pr√ºfen
                    ocr_marker = file_path + '.ocr_processed'
                    ocr_done = os.path.exists(ocr_marker)
                    
                    # Document Processing Status pr√ºfen
                    doc_processing_marker = file_path + '.doc_processed'
                    doc_processing_done = os.path.exists(doc_processing_marker)
                    
                    # Verarbeitung n√∂tig wenn:
                    # - Noch nicht in processed_files UND
                    # - (OCR fehlt ODER nicht in DB ODER Document Processing fehlt)
                    if (filename not in self.processed_files and 
                        (not ocr_done or not in_database or not doc_processing_done)):
                        files_to_process.append(filename)
            
            if not files_to_process:
                return  # Nichts zu tun
            
            logger.info(f"Dateien f√ºr Verarbeitung: {files_to_process}")
            
            # Dateien verarbeiten
            for filename in files_to_process:
                await self._process_single_file_complete(filename)
        
        except Exception as e:
            logger.error(f"Fehler beim Pr√ºfen der Dateien: {e}")
    
    def _is_file_in_database(self, filename: str) -> bool:
        """Pr√ºft ob Datei bereits in Datenbank ist."""
        try:
            from ..models.dokument import Dokument
            dokumente = Dokument.get_all()
            return any(d.dateiname == filename for d in dokumente)
        except Exception as e:
            logger.error(f"Fehler beim DB-Check: {e}")
            return False
    
    async def _process_single_file_complete(self, filename: str):
        """
        Vollst√§ndige Verarbeitung - kann mehrfach aufgerufen werden.
        √úberspringt bereits erledigte Schritte.
        """
        try:
            file_path = os.path.join(PDF_INPUT_DIR, filename)
            
            logger.info(f"üîÑ Verarbeite: {filename}")
            
            # Marker-Pfade
            ocr_marker = file_path + '.ocr_processed'
            doc_processing_marker = file_path + '.doc_processed'
            
            # 1. OCR falls n√∂tig
            if not os.path.exists(ocr_marker):
                logger.info(f"üìù Starte OCR: {filename}")
                success = await asyncio.to_thread(self._run_ocr_sync, file_path)
                
                if success:
                    # OCR-Marker erstellen
                    with open(ocr_marker, 'w') as marker:
                        marker.write(f"OCR: {os.path.getmtime(file_path)}")
                    logger.info(f"‚úÖ OCR abgeschlossen: {filename}")
                else:
                    logger.warning(f"‚ùå OCR fehlgeschlagen: {filename}")
                    return
            else:
                logger.debug(f"‚è≠Ô∏è  OCR bereits vorhanden: {filename}")
            
            # 2. Leerseiten-Entfernung (optional)
            try:
                await asyncio.to_thread(self._remove_blank_pages_pillow, file_path)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Leerseiten-Entfernung fehlgeschlagen: {e}")
            
            # 3. DB-Eintrag falls n√∂tig
            if not self._is_file_in_database(filename):
                logger.info(f"üìã F√ºge zur DB hinzu: {filename}")
                await self._add_to_database(filename, file_path)
            else:
                logger.debug(f"‚è≠Ô∏è  Bereits in DB: {filename}")
            
            # 4. Document Processing falls n√∂tig
            if not os.path.exists(doc_processing_marker):
                logger.info(f"üìÑ Starte Document Processing: {filename}")
                
                try:
                    if self._document_processor_manager:
                        doc_processed = await self._document_processor_manager.process_document(
                            file_path, filename
                        )
                        
                        # Document Processing Marker erstellen (egal ob erfolgreich oder nicht)
                        with open(doc_processing_marker, 'w') as marker:
                            marker.write(f"Doc Processing: {os.path.getmtime(file_path)}")
                        
                        if doc_processed:
                            logger.info(f"‚úÖ Document Processing erfolgreich: {filename}")
                        else:
                            logger.debug(f"‚ÑπÔ∏è  Kein Processor gefunden: {filename}")
                    else:
                        logger.debug("Document Processing System nicht verf√ºgbar")
                        # Trotzdem Marker erstellen
                        with open(doc_processing_marker, 'w') as marker:
                            marker.write(f"Doc Processing unavailable: {os.path.getmtime(file_path)}")
                            
                except Exception as e:
                    logger.error(f"Document Processing Fehler f√ºr {filename}: {e}")
                    # Marker trotzdem erstellen um endlose Wiederholung zu vermeiden
                    with open(doc_processing_marker, 'w') as marker:
                        marker.write(f"Doc Processing failed: {os.path.getmtime(file_path)}")
            else:
                logger.debug(f"‚è≠Ô∏è  Document Processing bereits erledigt: {filename}")
            
            # 5. Als vollst√§ndig verarbeitet markieren
            self.processed_files.add(filename)
            
            logger.info(f"‚ú® Vollst√§ndig verarbeitet: {filename}")
            
        except Exception as e:
            logger.error(f"Fehler bei Vollverarbeitung von {filename}: {e}")
    
    def _run_ocr_sync(self, file_path: str) -> bool:
        """Synchrone OCR-Ausf√ºhrung f√ºr asyncio.to_thread."""
        try:
            # Tempor√§re Datei f√ºr OCR-Output
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
                temp_path = temp_file.name
            
            try:
                # OCR-Verarbeitung
                success = OCRService.create_searchable_pdf(file_path, temp_path)
                
                if success:
                    # Original durch OCR-Version ersetzen
                    shutil.move(temp_path, file_path)
                    return True
                else:
                    return False
                    
            finally:
                # Tempor√§re Datei aufr√§umen
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                    
        except Exception as e:
            logger.error(f"Fehler beim synchronen OCR: {e}")
            return False
    
    def _remove_blank_pages_pillow(self, pdf_path: str) -> bool:
        """
        Entfernt leere Seiten mit Pillow (pixelbasierte Analyse).
        Zuverl√§ssiger als textbasierte Ans√§tze.
        """
        try:
            import io
            import shutil

            import fitz
            from PIL import Image
            
            doc = fitz.open(pdf_path)
            pages_to_remove = []
            original_page_count = len(doc)
            
            logger.info(f"Pr√ºfe {original_page_count} Seiten auf Leerheit: {os.path.basename(pdf_path)}")
            
            doc_closed = False
            
            try:
                for page_num in range(len(doc)):
                    page = doc[page_num]
                    
                    # Seite als Bild rendern (niedrige Aufl√∂sung f√ºr Performance)
                    pix = page.get_pixmap(matrix=fitz.Matrix(0.5, 0.5))  # 50% Gr√∂√üe
                    img_data = pix.tobytes("png")
                    
                    # Pillow-Image direkt aus Speicher erstellen
                    img = Image.open(io.BytesIO(img_data))
                    
                    # Zu Graustufen konvertieren f√ºr einfachere Analyse
                    img_gray = img.convert('L')
                    
                    # Histogramm erstellen
                    histogram = img_gray.histogram()
                    
                    # Pr√ºfen ob Seite fast nur wei√üe Pixel hat
                    total_pixels = img_gray.size[0] * img_gray.size[1]
                    white_pixels = sum(histogram[240:])  # Pixel mit Wert 240-255 (fast wei√ü)
                    white_ratio = white_pixels / total_pixels
                    
                    # Seite ist leer wenn >98% der Pixel wei√ü sind
                    is_blank = white_ratio > 0.98
                    
                    if is_blank:
                        pages_to_remove.append(page_num)
                        logger.debug(f"Seite {page_num + 1} ist leer (wei√ü: {white_ratio:.1%})")
                    
                    # Explizit Speicher freigeben
                    img.close()
                    img_gray.close()
                
                # Leere Seiten entfernen (von hinten nach vorne)
                removed_count = 0
                for page_num in reversed(pages_to_remove):
                    doc.delete_page(page_num)
                    removed_count += 1
                
                if removed_count > 0:
                    # In tempor√§re Datei speichern
                    with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_output:
                        temp_output_path = temp_output.name
                    
                    try:
                        doc.save(temp_output_path, deflate=True)
                        doc.close()
                        doc_closed = True
                        
                        # Original durch bereinigte Version ersetzen
                        shutil.move(temp_output_path, pdf_path)
                        
                        logger.info(f"üóëÔ∏è  Leerseiten entfernt: {removed_count} von {original_page_count} aus {os.path.basename(pdf_path)}")
                        return True
                        
                    except Exception as save_error:
                        logger.error(f"Fehler beim Speichern der bereinigten PDF: {save_error}")
                        if os.path.exists(temp_output_path):
                            os.remove(temp_output_path)
                        return False
                else:
                    logger.info(f"‚úÖ Keine leeren Seiten in {os.path.basename(pdf_path)}")
                    return False
                    
            finally:
                # Dokument schlie√üen falls noch nicht geschlossen
                if not doc_closed:
                    try:
                        doc.close()
                    except:
                        pass
            
        except Exception as e:
            logger.error(f"Fehler bei pixelbasierter Leerseiten-Entfernung: {e}")
            return False
    
    async def _add_to_database(self, filename: str, file_path: str):
        """F√ºgt neue Datei zur Datenbank hinzu falls noch nicht vorhanden."""
        try:
            # Pr√ºfen ob bereits in DB
            vorhandene = [d for d in Dokument.get_all() if d.dateiname == filename]
            
            if not vorhandene:
                # Vorschau-Text extrahieren
                preview_text = await asyncio.to_thread(
                    OCRService.extract_preview_text, file_path, 300
                )
                
                # In DB speichern
                Dokument.create(
                    dateiname=filename,
                    pfad=file_path,
                    inhalt_vorschau=preview_text
                )
                
                logger.info(f"üìã Datei zur Datenbank hinzugef√ºgt: {filename}")
        
        except Exception as e:
            logger.error(f"Fehler beim Hinzuf√ºgen zur DB: {e}")
    
    def force_check(self):
        """L√∂st eine sofortige Pr√ºfung aus (f√ºr manuellen Trigger)."""
        if self.running:
            # Erstelle Task f√ºr sofortige Pr√ºfung
            asyncio.create_task(self._check_and_process_files())
            logger.info("Manuelle OCR-Pr√ºfung mit Document Processing ausgel√∂st")


# Globale Scheduler-Instanz
ocr_scheduler = OCRScheduler(check_interval=30)  # Alle 30 Sekunden pr√ºfen